{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from __future__ import print_function\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "# get the data\r\n",
    "filname = '/Users/mprad/fer2013/fer2013.csv'\r\n",
    "label_map = ['Anger', 'Disgust', 'Fear', 'Happy', 'Sad', 'Surprise', 'Neutral']\r\n",
    "\r\n",
    "def getData(filname):\r\n",
    "    \r\n",
    "    Y = []\r\n",
    "    X = []\r\n",
    "    first = True\r\n",
    "    for line in open(filname):\r\n",
    "        if first:\r\n",
    "            first = False\r\n",
    "        else:\r\n",
    "            row = line.split(',')\r\n",
    "            Y.append(int(row[0]))\r\n",
    "            X.append([int(p) for p in row[1].split()])\r\n",
    "\r\n",
    "    X, Y = np.array(X) / 255.0, np.array(Y)\r\n",
    "    return X, Y\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "X, Y = getData(filname)\r\n",
    "num_class = len(set(Y))\r\n",
    "\r\n",
    "def balance_class(Y):\r\n",
    "    num_class = set(Y)\r\n",
    "    count_class = {}\r\n",
    "    for i in range(len(num_class)):\r\n",
    "        count_class[i] = sum([1 for y in Y if y == i])\r\n",
    "    return count_class\r\n",
    "\r\n",
    "balance = balance_class(Y)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# keras with tensorflow backend\r\n",
    "N, D = X.shape\r\n",
    "X = X.reshape(N, 48, 48, 1)\r\n",
    "\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1, random_state=0)\r\n",
    "y_train = (np.arange(num_class) == y_train[:, None]).astype(np.float32)\r\n",
    "y_test = (np.arange(num_class) == y_test[:, None]).astype(np.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import Dense , Activation , Dropout ,Flatten\r\n",
    "from keras.layers.convolutional import Conv2D\r\n",
    "from keras.layers.convolutional import MaxPooling2D\r\n",
    "from keras.metrics import categorical_accuracy\r\n",
    "from keras.models import model_from_json\r\n",
    "\r\n",
    "from keras.optimizers import *\r\n",
    "from keras.layers.normalization import BatchNormalization"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "batch_size = 128\r\n",
    "epochs = 124"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Main CNN model with four Convolution layer & two fully connected layer\r\n",
    "def baseline_model():\r\n",
    "    # Initialising the CNN\r\n",
    "    model = Sequential()\r\n",
    "\r\n",
    "    # 1 - Convolution\r\n",
    "    model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "    model.add(Dropout(0.25))\r\n",
    "\r\n",
    "    # 2nd Convolution layer\r\n",
    "    model.add(Conv2D(128,(5,5), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "    model.add(Dropout(0.25))\r\n",
    "\r\n",
    "    # 3rd Convolution layer\r\n",
    "    model.add(Conv2D(512,(3,3), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "    model.add(Dropout(0.25))\r\n",
    "\r\n",
    "    # 4th Convolution layer\r\n",
    "    model.add(Conv2D(512,(3,3), padding='same'))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\r\n",
    "    model.add(Dropout(0.25))\r\n",
    "\r\n",
    "\r\n",
    "    # Flattening\r\n",
    "    model.add(Flatten())\r\n",
    "\r\n",
    "    # Fully connected layer 1st layer\r\n",
    "    model.add(Dense(256))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(Dropout(0.25))\r\n",
    "\r\n",
    "\r\n",
    "    # Fully connected layer 2nd layer\r\n",
    "    model.add(Dense(512))\r\n",
    "    model.add(BatchNormalization())\r\n",
    "    model.add(Activation('relu'))\r\n",
    "    model.add(Dropout(0.25))\r\n",
    "\r\n",
    "    model.add(Dense(num_class, activation='sigmoid'))\r\n",
    "\r\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[categorical_accuracy])\r\n",
    "    return model\r\n",
    "\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "def baseline_model_saved():\r\n",
    "   \r\n",
    "    json_file = open('/Users/mprad/Downloads/model_4layer_2_2_pool.json', 'r')\r\n",
    "    loaded_model_json = json_file.read()\r\n",
    "    json_file.close()\r\n",
    "    model = model_from_json(loaded_model_json)\r\n",
    "\r\n",
    "    model.load_weights(\"/Users/mprad/Downloads/model_4layer_2_2_pool.h5\")\r\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[categorical_accuracy])\r\n",
    "    return model\r\n",
    "\r\n",
    "\r\n",
    "is_model_saved = True\r\n",
    "\r\n",
    "\r\n",
    "if(is_model_saved==False ):\r\n",
    "    # Train model\r\n",
    "    model = baseline_model()\r\n",
    "    \r\n",
    "    model.fit(X_train, y_train,\r\n",
    "              batch_size=batch_size,\r\n",
    "              epochs=epochs,\r\n",
    "              verbose=2,\r\n",
    "              validation_split=0.1111)\r\n",
    "    model_json = model.to_json()\r\n",
    "    with open(\"model_4layer_2_2_pool.json\", \"w\") as json_file:\r\n",
    "        json_file.write(model_json)\r\n",
    "    \r\n",
    "    model.save_weights(\"model_4layer_2_2_pool.h5\")\r\n",
    "    print(\"Saved model to disk\")\r\n",
    "else:\r\n",
    "    # Load the trained model\r\n",
    "    print(\"Load model from disk\")\r\n",
    "    model = baseline_model_saved()\r\n",
    "\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Load model from disk\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "score = model.predict(X_test)\r\n",
    "print (model.summary())\r\n",
    "\r\n",
    "new_X = [ np.argmax(item) for item in score ]\r\n",
    "y_test2 = [ np.argmax(item) for item in y_test]\r\n",
    "\r\n",
    "# Calculating categorical accuracy taking label having highest probability\r\n",
    "accuracy = [ (x==y) for x,y in zip(new_X,y_test2) ]\r\n",
    "print(\" Accuracy on Test set : \" , np.mean(accuracy))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 128)       204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 512)       590336    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 12, 12, 512)       2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 12, 12, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1179904   \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 7)                 3591      \n",
      "=================================================================\n",
      "Total params: 4,478,727\n",
      "Trainable params: 4,474,759\n",
      "Non-trainable params: 3,968\n",
      "_________________________________________________________________\n",
      "None\n",
      " Accuracy on Test set :  0.6544998606854276\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}